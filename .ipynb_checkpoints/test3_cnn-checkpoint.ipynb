{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d8c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf37e666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>상처</td>\n",
       "      <td>data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000010...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000001...\n",
       "1       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000002...\n",
       "2       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000003...\n",
       "3       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000004...\n",
       "4       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000005...\n",
       "5       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000006...\n",
       "6       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000007...\n",
       "7       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000008...\n",
       "8       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000009...\n",
       "9       상처  data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/M_000010..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/감성대화/감성대화말뭉치_table.xlsx')\n",
    "data2 = data.loc[:,['감정_대분류','NO.']]\n",
    "data2.columns = ['Emotions','Path']\n",
    "data2['Path'] = 'data/감성대화/감성대화말뭉치AI데이터_Wave_남자성우_5000/'+data2['Path']+'.wav'\n",
    "\n",
    "data_path = data2[data2['Emotions']!='당황']\n",
    "data_path.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7947465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 52376 (\\N{HANGUL SYLLABLE CEO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 49256 (\\N{HANGUL SYLLABLE BBEUM}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 48520 (\\N{HANGUL SYLLABLE BUL}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 50504 (\\N{HANGUL SYLLABLE AN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 45432 (\\N{HANGUL SYLLABLE NO}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 49836 (\\N{HANGUL SYLLABLE SEUL}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\y2657\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 54548 (\\N{HANGUL SYLLABLE PEUM}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEbCAYAAADAsRPLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbH0lEQVR4nO3df7wddX3n8debRKKAlEQDIkEJa2oFd6U1TbG2yhYr6dYa7JYaV22wWOoutqJ9tCXdVdA2q21Xu12V2qy1xLUaU6sStUViFPyxVhrRagNGIuFHmkAuv1RQosFP/5hJ78llbnJvcu/c29zX8/E4jzPzne/MfM4kj/M+850596SqkCRppCOmugBJ0vRkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJowSZ6RZF2SHUm+l+TuJBuSrEgya4prOyXJZUlOneDtPi7J+iT3JKkkF+9n/7WfxxkTWdcY6r44yS92tF+WxHvfBcDsqS5Ah4f2jfEtwCeB3wVuBeYCzwX+DLgPuHKKygM4BbgU+Cxw8wRu93XAs4HzgZ3ALQfo/0ZgfUf71yewprG4mOZYfHBE+zuBq3quRdOUAaFDluRZNOHwtqr6zRGLr0zyFuDo/ivrxVOAf6yqD42x/81V9feTWdChqKrtwPaprkPTg0NMmgiXAPcAv9O1sKq+UVVf2TufZEmSTyS5P8kDSTYmWTK4TpJrklwzcltJbklyxcD8+e0QzZlJ/irJt9ohrv+T5JFtn7OAT7WrbBgY1jlrtBeUxquTbGmHy3YmeVuSY9vlp7RDMWcBPz2wzVMOdLD2Z2Ao6hVJ3pjkjiTfTvKeJEcleVKSj7fHbmuSFR3bWJrk80m+m+SbST6c5MmDxxB4IvDigbqvaJc9bIgpybHta9+RZHd7TF6dJAN9zmq38/y2711Jhtq6jxuxvVclubGt794km5K84FCOmyaHAaFD0l5bOAu4uqoeHEP//wBcSzP8dD7wK8CxwLVJnnYIpfw/4BvAL9IMaV0ErGyXXd/OA/wm8Iz2cf1+treK5qxoA/ALwB+19X4syRE0w0nPAL4CfGlgmzsPUOcRSWaPeHRdn1kJPB5YQTOM9ULgHcCHgI8BL2j3/ZdJTt+7UpKl7fL723X+K/BU4LNJTmq7vQC4A/j4QN2/31Vs+1o/BrwMeHN7LK5qj82qjlX+FCjgvwBvAP5z27Z3ey9ut/M+4D8BLwY+AMzrPlyaUlXlw8dBP4ATaN4Q3jjG/h+guR5x3EDbsTRnIB8caLsGuKZj/VuAKwbmz2/3//oR/T4KfH1g/qy233PGUOM84MHB/bTtL2m38fyBts921dmxzVPadbse93f0++SI9T/Ytr9koG0usAe4dKBtE3ATMHugbSHwfeAtI47jezrqvKx5W/jX+ee1+z1/RL93AruBx444vmtG9HtbeywzMH/9VP+/9TG2h2cQ6tuzgI9W1X17G6rqWzQXbp99CNv92Ij5rwJPOMhtnQnMAd4zon0tzRvyodT5B8CPj3j8dEe/vxsx/7X2+eN7G6rqXmAXcDJAkqOBHwPeX1V7BvptAz53kHU/C/gBzSf+Qe8BjqQ5+xjU9e8wh+aDBMA/AGckeWuS5yQ56iBqUk+8SK1DdTfwXZox7bGYR/cwzB00n4gP1j0j5nfTvDEdjL3DHfvUWVV7ktzNoQ2H3FpVm8bQ794R89/bT/sj2+m5QBj9+I7132jQPOCeqtrdsb29ywd1/TswUOO72+kLgP8GfD/J3wKvqapbDqI+TSLPIHRI2k+q1wA/m2Qsb8j3AI/raH8c+765PEjzCXWkPsaq99axT51JZgOPoQnF6ehemmGe0Y7vwdR9DzAvych/i737GNc2q/HnVbUEeCzNNZYlwPsPojZNMgNCE+FNNG+cf9y1MMnC9uI0NBeofz7JoweWP5rm4ue1A6vdCvzw4BtTezvtozk4ez/JPmoMff++7b98RPsLac66r33YGtNAVT0AfBE4b/DCd5InAj/JvnXvZmzH4lqa94nzRrS/mObs5aBv2a2qe6vq/cA6mgvpmmYcYtIhq6pPJ3kN8JYkTwGuAG6jGfI4G3g5zV0tX6G5W+Z5wMYkf0jzifd3gaNo7nrZay1wIfCu9hbMhcBrgG8eZJlfp7l+8KtJ7qF5g9xSVd/ueD33tN/dWJnkAeBvab7v8Ac0F6VHjrOPx6lJzuyqr6pGDs8cjNfS1PfRJJcDxwCvpzlubx7odwPN7bnPoxkuumuUIZ6/o3nN70gyH9hMc/fRy2luTLhrPMUlWQ18G/g8zfWTHwZeClw9nu2oJ1N9ldzH4fOg+ZT61zRj4N+nGZ64mubunyMG+v0E8AmaWzEfADYCSzq29+s0d+R8F/j/wNMZ/S6mJ41Y9zIG7sYZ2N7NNEFRwFn7eS0BXg1sofmkvBN4O3DsiH4TcRdTAb80ot/Lu14PA3cnte23MOJuJGApzRvwd2mC4UrgySP6/AjwGeA77Xav2M9xO5bm7qOd7bH4entsMtDnLDruEhv49zmlnV9BMyS5iyaktwF/MvK4+pgej723nkmStA+vQUiSOhkQkqROBoQkqZMBIUnqdNjc5rp06dK66ir/jL0kjVNGW3DYnEHcdde4bseWJB3AYRMQkqSJZUBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSep02PypDUkH79pnPXuqS5hwz/70wf0y7Nt+6yMTXMnUe+Wbf+Gg1jMgNGM9863PnOoSJsXnfuNzU12CDhMOMUmSOhkQkqRODjHNMLe94d9PdQmT4gmv++pUlyAddjyDkCR1mhFnEE//7XdPdQmT4ot//CtTXYKkw5hnEJKkTr0FRJJXJ9mc5J+SvC/JI5PMS7IhyU3t89yB/iuTbE2yJck5fdUpSWr0EhBJTgJ+E1hcVU8FZgHLgUuAjVW1CNjYzpPktHb56cBS4PIks/qoVZLU6HOIaTbwqCSzgaOAHcAyYE27fA1wbju9DFhbVburahuwFVjSY62SNOP1EhBV9c/A/wJuA3YC36yqq4ETqmpn22cncHy7yknA7QOb2N627SPJhUk2Jdk0NDQ0mS9BkmacvoaY5tKcFSwEHg8cneQl+1ulo60e1lC1uqoWV9Xi+fPnT0yxkiSgvyGm5wDbqmqoqr4PfBD4SeDOJCcCtM+72v7bgZMH1l9AMyQlSepJXwFxG3BmkqOSBDgbuBFYD6xo+6wArmyn1wPLk8xJshBYBFzXU62SJHr6olxVfSHJB4DrgT3Al4DVwDHAuiQX0ITIeW3/zUnWATe0/S+qqof6qFWS1Ojtm9RVdSlw6Yjm3TRnE139VwGrJrsuSVI3v0ktSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROff0m9ZOTfHng8a0kFyeZl2RDkpva57kD66xMsjXJliTn9FGnJGlYLwFRVVuq6oyqOgN4OvAd4EPAJcDGqloEbGznSXIasBw4HVgKXJ5kVh+1SpIaUzHEdDbwjaq6FVgGrGnb1wDnttPLgLVVtbuqtgFbgSV9FypJM9lUBMRy4H3t9AlVtROgfT6+bT8JuH1gne1t2z6SXJhkU5JNQ0NDk1iyJM08vQZEkiOB5wN/faCuHW31sIaq1VW1uKoWz58/fyJKlCS1+j6D+Dng+qq6s52/M8mJAO3zrrZ9O3DywHoLgB29VSlJ6j0gXsTw8BLAemBFO70CuHKgfXmSOUkWAouA63qrUpLE7L52lOQo4GeBXx9ofhOwLskFwG3AeQBVtTnJOuAGYA9wUVU91FetkqQeA6KqvgM8ZkTb3TR3NXX1XwWs6qE0SVIHv0ktSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROBoQkqVNvAZHkuCQfSPK1JDcmeUaSeUk2JLmpfZ470H9lkq1JtiQ5p686JUmNPs8g/hS4qqp+BHgacCNwCbCxqhYBG9t5kpwGLAdOB5YClyeZ1WOtkjTj9RIQSY4FngX8BUBVfa+q7gOWAWvabmuAc9vpZcDaqtpdVduArcCSPmqVJDX6OoM4FRgC/jLJl5K8M8nRwAlVtROgfT6+7X8ScPvA+tvbtn0kuTDJpiSbhoaGJvcVSNIM01dAzAZ+DPizqvpR4AHa4aRRpKOtHtZQtbqqFlfV4vnz509MpZIkoL+A2A5sr6ovtPMfoAmMO5OcCNA+7xrof/LA+guAHT3VKkmip4CoqjuA25M8uW06G7gBWA+saNtWAFe20+uB5UnmJFkILAKu66NWSVJjdo/7+g3gr5IcCdwMvIwmoNYluQC4DTgPoKo2J1lHEyJ7gIuq6qEea5WkGa+3gKiqLwOLOxadPUr/VcCqyaxJkjQ6v0ktSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROvQVEkluSfDXJl5NsatvmJdmQ5Kb2ee5A/5VJtibZkuScvuqUJDX6PoP4j1V1RlXt/eGgS4CNVbUI2NjOk+Q0YDlwOrAUuDzJrJ5rlaQZbcwBkeS8Udp/6RD2vwxY006vAc4daF9bVburahuwFVhyCPuRJI3TeM4g/mKU9tVjXL+Aq5N8McmFbdsJVbUToH0+vm0/Cbh9YN3tbds+klyYZFOSTUNDQ2MsQ5I0Fgf8Teokp7aTRyRZCGRg8anAg2Pc1zOrakeS44ENSb62v912tNXDGqpW0wbU4sWLH7ZcknTwDhgQNMM7RfOm/Y0Ry+4ALhvLjqpqR/u8K8mHaIaM7kxyYlXtTHIisKvtvh04eWD1BcCOsexHkjQxDjjEVFVHVNUs4DPt9ODj8e2n+P1KcnSSR++dBp4L/BOwHljRdlsBXNlOrweWJ5nTnrUsAq4b96uTJB20sZxBAFBVzz6E/ZwAfCjJ3n2+t6quSvIPwLokFwC3Aee1+9qcZB1wA7AHuKiqHjqE/UuSxmnMAdF+kl8FnAEcM7isqp6wv3Wr6mbgaR3tdwNnj7LOqnZ/kqQpMOaAAN5Lcw3it4DvTE45kqTpYjwBcTrNnUg/mKxiJEnTx3i+B/Fp4EcnqxBJ0vQynjOIW4CPJ/kgze2t/6qqXjeRRUmSpt54AuJo4CPAI9j3OwqSpMPQeG5zfdlkFiJJml7Gc5vrqaMta29jlSQdRsYzxDT4Jzf22vv3j/xT3JJ0mBnPENM+dzwleRxwKfCZiS5KkjT1DvoHg6rqDuBi4I0TVo0kado41F+UezJw1EQUIkmaXsZzkfoz7PubDEfRfLv6DRNdlCRp6o3nIvU7R8w/APxjVd00gfVIkqaJ8VykXnPgXpKkw8WYr0EkeUSS1ye5OcmD7fPrkxw5mQVKkqbGeIaY/ojmZ0JfAdwKPBF4LXAs8OqJL02SNJXGcxfTecDzq+rqqtpSVVcDLwB+eawbSDIryZeSfLSdn5dkQ5Kb2ue5A31XJtmaZEuSc8ZRpyRpAownIDLO9i6vAm4cmL8E2FhVi4CN7TxJTgOW09wltRS4PInf1pakHo0nIP4a+EiSc5I8JclS4MNt+wElWQD8PPveDbUM2Hvxew1w7kD72qraXVXbaP7Mx5Jx1CpJOkTjCYjfAT4BvB34IvBW4JPAb49x/f/dbmPwF+lOqKqdAO3z8W37ScDtA/22t237SHJhkk1JNg0NDY39lUiSDuiAAZHkmUn+sKq+V1Wvq6onVdVR7bDQHODHxrCN5wG7quqLY6yra9iqHtZQtbqqFlfV4vnz549x05KksRjLGcTv0fzcaJdPAf99DNt4JvD8JLcAa4GfSfIe4M4kJwK0z7va/tvZ90eJFgA7xrAfSdIEGUtAnAFcNcqyTwBPP9AGqmplVS2oqlNoLj5/sqpeAqwHVrTdVgBXttPrgeVJ5iRZCCwCrhtDrZKkCTKW70EcCxwJfLdj2SOARx/C/t8ErEtyAXAbza20VNXmJOuAG4A9wEVV9dAh7EeSNE5jCYivAc9l+NP9oOe2y8esqq4Brmmn7wbOHqXfKmDVeLYtSZo4YwmIPwH+vP0ewoer6gdJjqC5JfXtwGsmsT5J0hQ5YEBU1XvbX49bA8xJchfwWOBB4NKqet8k1yhJmgJj+ltMVfWWJO8EngE8Brgb+HxVfWsyi5MkTZ3x/LnvbwEfn8RaJEnTyKH+5Kgk6TBlQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE69BESSRya5Lsk/Jtmc5PVt+7wkG5Lc1D7PHVhnZZKtSbYkOaePOiVJw/o6g9gN/ExVPY3mJ0yXJjkTuATYWFWLgI3tPElOo/lp0tOBpcDl7e9RSJJ60ktAVOP+dvYR7aOAZTS/M0H7fG47vQxYW1W7q2obsBVY0ketkqRGb9cgksxK8mVgF7Chqr4AnFBVOwHa5+Pb7icBtw+svr1tG7nNC5NsSrJpaGhoUuuXpJmmt4Coqoeq6gxgAbAkyVP30z1dm+jY5uqqWlxVi+fPnz9BlUqSYAruYqqq+4BraK4t3JnkRID2eVfbbTtw8sBqC4Ad/VUpSerrLqb5SY5rpx8FPAf4GrAeWNF2WwFc2U6vB5YnmZNkIbAIuK6PWiVJjTH/5OghOhFY096JdASwrqo+muTzwLokFwC3AecBVNXmJOuAG4A9wEVV9VBPtUqS6CkgquorwI92tN8NnD3KOquAVZNcmiRpFH6TWpLUyYCQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVKnvn5y9OQkn0pyY5LNSV7Vts9LsiHJTe3z3IF1VibZmmRLknP6qFOSNKyvM4g9wG9V1VOAM4GLkpwGXAJsrKpFwMZ2nnbZcuB0YClweftzpZKknvQSEFW1s6qub6e/DdwInAQsA9a03dYA57bTy4C1VbW7qrYBW4ElfdQqSWr0fg0iySk0v0/9BeCEqtoJTYgAx7fdTgJuH1hte9s2clsXJtmUZNPQ0NCk1i1JM02vAZHkGOBvgIur6lv769rRVg9rqFpdVYuravH8+fMnqkxJEj0GRJJH0ITDX1XVB9vmO5Oc2C4/EdjVtm8HTh5YfQGwo69aJUn93cUU4C+AG6vqLQOL1gMr2ukVwJUD7cuTzEmyEFgEXNdHrZKkxuye9vNM4KXAV5N8uW37PeBNwLokFwC3AecBVNXmJOuAG2jugLqoqh7qqVZJEj0FRFV9lu7rCgBnj7LOKmDVpBUlSdovv0ktSepkQEiSOhkQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6GRCSpE4GhCSpkwEhSepkQEiSOhkQkqROff2i3LuS7EryTwNt85JsSHJT+zx3YNnKJFuTbElyTh81SpL21dcZxBXA0hFtlwAbq2oRsLGdJ8lpwHLg9Hady5PM6qlOSVKrl4Coqk8D94xoXgasaafXAOcOtK+tqt1VtQ3YCizpo05J0rCpvAZxQlXtBGifj2/bTwJuH+i3vW17mCQXJtmUZNPQ0NCkFitJM810vEjd9dvV1dWxqlZX1eKqWjx//vxJLkuSZpapDIg7k5wI0D7vatu3AycP9FsA7Oi5Nkma8aYyINYDK9rpFcCVA+3Lk8xJshBYBFw3BfVJ0ow2u4+dJHkfcBbw2CTbgUuBNwHrklwA3AacB1BVm5OsA24A9gAXVdVDfdQpSRrWS0BU1YtGWXT2KP1XAasmryJJ0oFMx4vUkqRpwICQJHUyICRJnQwISVInA0KS1MmAkCR1MiAkSZ0MCElSJwNCktTJgJAkdTIgJEmdDAhJUicDQpLUyYCQJHUyICRJnQwISVKnaR0QSZYm2ZJka5JLproeSZpJpm1AJJkFvB34OeA04EVJTpvaqiRp5pi2AQEsAbZW1c1V9T1gLbBsimuSpBkjVTXVNXRK8kvA0qp6eTv/UuAnquqVA30uBC5sZ58MbOm90Id7LHDXVBcxTXgshnkshnkshk2HY3FXVS3tWjC770rGIR1t+6RZVa0GVvdTztgk2VRVi6e6junAYzHMYzHMYzFsuh+L6TzEtB04eWB+AbBjimqRpBlnOgfEPwCLkixMciSwHFg/xTVJ0owxbYeYqmpPklcCHwdmAe+qqs1TXNZYTKshrynmsRjmsRjmsRg2rY/FtL1ILUmaWtN5iEmSNIUMCElSJwNCktRp2l6knu6SXAacCexpm2YDf9/VVlWX9V1fnzwWwzwWwzwWw/6tHgsD4tAsr6r7AJIcB1w8SttM4LEY5rEY5rEY9m/uWDjEJEnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6eZvrwdsFvDvJD9r5I4CrRmk73Hkshnkshnkshv2bPBb+sT5JUieHmCRJnQwISVInA0KS1MmAkHqW5B1JXjvVdUgH4kVqzVhJbgFOAB4aaL6iql45gfs4H3h5Vf3URG1T6ou3uWqm+4Wq+sRUFyFNRw4xSSMkOT/J55L8SZL7ktyc5Cfb9tuT7EqyYqD/DyV5d5KhJLcm+R9JjkjyFOAdwDOS3J/kvrb/FUn+YGD9X0uyNck9SdYnefzAskryiiQ3Jbk3yduTpF32pCTXJvlmkruSvL+3g6QZwYCQuv0E8BXgMcB7gbXAjwNPAl4CvC3JMW3ftwI/BJwKPBv4FeBlVXUj8Arg81V1TFUdN3InSX4GeCPwy8CJwK3tvgY9r93309p+57Ttvw9cDcwFFrR1SBPGgNBM9+H2LGHv49fa9m1V9ZdV9RDwfuBk4A1Vtbuqrga+BzwpySzghcDKqvp2Vd0CvBl46Rj3/2LgXVV1fVXtBlbSnHGcMtDnTVV1X1XdBnwKOKNt/z7wRODxVfVgVX32II+B1MmA0Ex3blUdN/D4v237nQN9vgtQVSPbjgEeCxxJ88l/r1uBk8a4/8cPrltV9wN3j1j/joHp77T7BfgdIMB1STYn+dUx7lMaEy9SS4fmLoY/yd/Qtj0B+Od2+kC3Ce5o1wUgydE0w1r/POoaezdcdQfwa+16PwV8Ismnq2rreF6ANBrPIKRD0A5BrQNWJXl0kicCrwHe03a5E1iQ5MhRNvFe4GVJzkgyB/ifwBfaoar9SnJekgXt7L00YfTQflaRxsWA0Ez3kfYOo72PDx3ENn4DeAC4GfgszZv+u9plnwQ2A3ckuWvkilW1EXgt8DfATuDfAcvHuN8fB76Q5H5gPfCqqtp2EPVLnfyinCSpk2cQkqROBoQkqZMBIUnqZEBIkjoZEJKkTgaEJKmTASFJ6mRASJI6/QuZmxuoxNaXCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(data_path.Emotions)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c3ca54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, e):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50fc804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def extract_features(data):\n",
    "\n",
    "    result = np.array([])\n",
    "\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    \n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    \n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2))\n",
    "\n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85135a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y2657\\AppData\\Local\\Temp\\ipykernel_3952\\2780010524.py:8: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "C:\\Users\\y2657\\AppData\\Local\\Temp\\ipykernel_3952\\2780010524.py:15: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "C:\\Users\\y2657\\AppData\\Local\\Temp\\ipykernel_3952\\2780010524.py:8: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n",
      "C:\\Users\\y2657\\AppData\\Local\\Temp\\ipykernel_3952\\2780010524.py:15: FutureWarning: Pass sr=22050, n_steps=0.7 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
      "C:\\Users\\y2657\\AppData\\Local\\Temp\\ipykernel_3952\\2780010524.py:8: FutureWarning: Pass rate=0.8 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.effects.time_stretch(data, rate)\n"
     ]
    }
   ],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in zip(data_path.Path, data_path.Emotions):\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8cdef80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12525, 12525)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "992ff77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-306.114288</td>\n",
       "      <td>112.489784</td>\n",
       "      <td>9.656166</td>\n",
       "      <td>20.976927</td>\n",
       "      <td>10.871535</td>\n",
       "      <td>1.714456</td>\n",
       "      <td>9.115148</td>\n",
       "      <td>3.485343</td>\n",
       "      <td>-9.294915</td>\n",
       "      <td>0.956282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>상처</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-227.204862</td>\n",
       "      <td>67.134218</td>\n",
       "      <td>16.748915</td>\n",
       "      <td>14.731566</td>\n",
       "      <td>8.504826</td>\n",
       "      <td>3.021036</td>\n",
       "      <td>6.716599</td>\n",
       "      <td>-0.455921</td>\n",
       "      <td>-6.608128</td>\n",
       "      <td>-3.570164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>상처</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-357.489227</td>\n",
       "      <td>110.233650</td>\n",
       "      <td>6.194149</td>\n",
       "      <td>21.282358</td>\n",
       "      <td>8.312746</td>\n",
       "      <td>1.508243</td>\n",
       "      <td>10.240339</td>\n",
       "      <td>-1.523876</td>\n",
       "      <td>-9.824450</td>\n",
       "      <td>-0.574490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>상처</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-327.534180</td>\n",
       "      <td>85.773712</td>\n",
       "      <td>21.447964</td>\n",
       "      <td>26.183439</td>\n",
       "      <td>15.070938</td>\n",
       "      <td>5.446004</td>\n",
       "      <td>7.238493</td>\n",
       "      <td>7.339557</td>\n",
       "      <td>-3.088352</td>\n",
       "      <td>0.537832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>상처</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-290.312946</td>\n",
       "      <td>68.863975</td>\n",
       "      <td>21.035985</td>\n",
       "      <td>24.472799</td>\n",
       "      <td>14.911182</td>\n",
       "      <td>3.966073</td>\n",
       "      <td>5.799951</td>\n",
       "      <td>5.845721</td>\n",
       "      <td>-2.336216</td>\n",
       "      <td>-1.560404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>상처</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4         5  \\\n",
       "0 -306.114288  112.489784   9.656166  20.976927  10.871535  1.714456   \n",
       "1 -227.204862   67.134218  16.748915  14.731566   8.504826  3.021036   \n",
       "2 -357.489227  110.233650   6.194149  21.282358   8.312746  1.508243   \n",
       "3 -327.534180   85.773712  21.447964  26.183439  15.070938  5.446004   \n",
       "4 -290.312946   68.863975  21.035985  24.472799  14.911182  3.966073   \n",
       "\n",
       "           6         7         8         9  ...       139       140       141  \\\n",
       "0   9.115148  3.485343 -9.294915  0.956282  ...  0.002338  0.001411  0.002440   \n",
       "1   6.716599 -0.455921 -6.608128 -3.570164  ...  0.003648  0.002740  0.003756   \n",
       "2  10.240339 -1.523876 -9.824450 -0.574490  ...  0.000617  0.000666  0.000399   \n",
       "3   7.238493  7.339557 -3.088352  0.537832  ...  0.006482  0.002612  0.004906   \n",
       "4   5.799951  5.845721 -2.336216 -1.560404  ...  0.006670  0.002710  0.004992   \n",
       "\n",
       "        142       143       144       145       146       147  labels  \n",
       "0  0.002662  0.001982  0.001813  0.001536  0.000450  0.000036      상처  \n",
       "1  0.004153  0.003416  0.003228  0.002930  0.001870  0.001440      상처  \n",
       "2  0.000360  0.000597  0.000393  0.000235  0.000094  0.000008      상처  \n",
       "3  0.004633  0.004013  0.003693  0.001869  0.000751  0.000059      상처  \n",
       "4  0.004684  0.004073  0.003731  0.001954  0.000854  0.000164      상처  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('features.csv', index=False)\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d8c98348",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67b543e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2581160a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9393, 148), (9393, 5), (3132, 148), (3132, 5))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ea17552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9393, 148), (9393, 5), (3132, 148), (3132, 5))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 및 테스트데이터 갯수 확인\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77a0e9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9393, 148, 1), (9393, 5), (3132, 148, 1), (3132, 5))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 차원 모델에 맞게 통일 \n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7169a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 텐서로 변환\n",
    "x_tensor = torch.tensor(x_train, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float)\n",
    "\n",
    "# Dataset 생성\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# DataLoader 생성\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float)\n",
    "\n",
    "dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98ac9539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mymodel(\n",
      "  (conv1): Conv1d(148, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (pool): MaxPool1d(kernel_size=5, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv3): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv4): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b57c32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=148, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=5, stride=2, padding=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=5, stride=2, padding=2)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=128, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=5, stride=2, padding=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64, 32)  # Calculate the correct input size after convolutions and poolings\n",
    "        self.dropout2 = nn.Dropout(p=0.6)\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool4(torch.relu(self.conv4(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "23826446",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94de9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "for epo in range(epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    for i,(x,y) in enumerate(dataloader):\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aedd9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6106e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.356219  [    0/ 9393]\n",
      "loss: 1.386240  [ 3200/ 9393]\n",
      "loss: 1.617358  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.044676 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.427076  [    0/ 9393]\n",
      "loss: 1.341586  [ 3200/ 9393]\n",
      "loss: 1.354878  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 0.044825 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.528735  [    0/ 9393]\n",
      "loss: 1.215977  [ 3200/ 9393]\n",
      "loss: 1.484633  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.044289 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.345588  [    0/ 9393]\n",
      "loss: 1.432200  [ 3200/ 9393]\n",
      "loss: 1.264677  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.043839 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.282375  [    0/ 9393]\n",
      "loss: 1.470721  [ 3200/ 9393]\n",
      "loss: 1.339354  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.044067 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.303115  [    0/ 9393]\n",
      "loss: 1.307699  [ 3200/ 9393]\n",
      "loss: 1.287974  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.042630 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.404032  [    0/ 9393]\n",
      "loss: 1.372675  [ 3200/ 9393]\n",
      "loss: 1.331498  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.042614 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.162124  [    0/ 9393]\n",
      "loss: 1.152251  [ 3200/ 9393]\n",
      "loss: 1.258873  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.042077 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.354008  [    0/ 9393]\n",
      "loss: 1.381346  [ 3200/ 9393]\n",
      "loss: 1.284755  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 0.043698 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.381697  [    0/ 9393]\n",
      "loss: 1.358284  [ 3200/ 9393]\n",
      "loss: 1.292450  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.042436 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.259710  [    0/ 9393]\n",
      "loss: 1.382031  [ 3200/ 9393]\n",
      "loss: 1.311724  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 0.042283 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.170241  [    0/ 9393]\n",
      "loss: 1.311944  [ 3200/ 9393]\n",
      "loss: 1.188609  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 0.042309 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.256393  [    0/ 9393]\n",
      "loss: 1.406944  [ 3200/ 9393]\n",
      "loss: 1.422357  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.041869 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.159605  [    0/ 9393]\n",
      "loss: 1.357490  [ 3200/ 9393]\n",
      "loss: 1.300836  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.041559 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.242525  [    0/ 9393]\n",
      "loss: 1.254247  [ 3200/ 9393]\n",
      "loss: 1.257125  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.041918 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.302768  [    0/ 9393]\n",
      "loss: 1.219931  [ 3200/ 9393]\n",
      "loss: 1.332744  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.041372 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.211176  [    0/ 9393]\n",
      "loss: 1.178768  [ 3200/ 9393]\n",
      "loss: 1.338428  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 0.041786 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.286479  [    0/ 9393]\n",
      "loss: 1.339757  [ 3200/ 9393]\n",
      "loss: 1.301950  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 0.041381 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.146164  [    0/ 9393]\n",
      "loss: 1.160071  [ 3200/ 9393]\n",
      "loss: 1.252096  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.041772 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.240007  [    0/ 9393]\n",
      "loss: 1.395297  [ 3200/ 9393]\n",
      "loss: 1.186214  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.042807 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.172285  [    0/ 9393]\n",
      "loss: 1.373867  [ 3200/ 9393]\n",
      "loss: 1.306876  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.042262 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.392395  [    0/ 9393]\n",
      "loss: 1.428805  [ 3200/ 9393]\n",
      "loss: 1.248585  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 0.041257 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.247867  [    0/ 9393]\n",
      "loss: 1.190133  [ 3200/ 9393]\n",
      "loss: 1.163028  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 0.040628 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.253838  [    0/ 9393]\n",
      "loss: 1.095341  [ 3200/ 9393]\n",
      "loss: 1.281617  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.041601 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.185857  [    0/ 9393]\n",
      "loss: 1.218408  [ 3200/ 9393]\n",
      "loss: 1.233254  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.041135 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.329394  [    0/ 9393]\n",
      "loss: 1.282712  [ 3200/ 9393]\n",
      "loss: 1.272575  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.041189 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.221270  [    0/ 9393]\n",
      "loss: 1.233232  [ 3200/ 9393]\n",
      "loss: 1.161492  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.041458 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.436022  [    0/ 9393]\n",
      "loss: 1.238693  [ 3200/ 9393]\n",
      "loss: 1.242377  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.040410 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.185329  [    0/ 9393]\n",
      "loss: 1.202243  [ 3200/ 9393]\n",
      "loss: 1.270299  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.040624 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.199525  [    0/ 9393]\n",
      "loss: 1.198661  [ 3200/ 9393]\n",
      "loss: 1.264243  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 0.041346 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.240892  [    0/ 9393]\n",
      "loss: 1.251347  [ 3200/ 9393]\n",
      "loss: 1.185244  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.040367 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.087049  [    0/ 9393]\n",
      "loss: 1.420923  [ 3200/ 9393]\n",
      "loss: 1.180781  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.040779 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.089595  [    0/ 9393]\n",
      "loss: 1.284006  [ 3200/ 9393]\n",
      "loss: 1.276884  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.040985 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.403743  [    0/ 9393]\n",
      "loss: 1.248598  [ 3200/ 9393]\n",
      "loss: 1.278009  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 0.041068 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.215643  [    0/ 9393]\n",
      "loss: 1.274204  [ 3200/ 9393]\n",
      "loss: 1.286488  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.040165 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.119938  [    0/ 9393]\n",
      "loss: 1.093297  [ 3200/ 9393]\n",
      "loss: 1.225746  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.040323 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.222888  [    0/ 9393]\n",
      "loss: 1.188842  [ 3200/ 9393]\n",
      "loss: 1.328044  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.040990 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.295910  [    0/ 9393]\n",
      "loss: 1.186253  [ 3200/ 9393]\n",
      "loss: 1.157451  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.041350 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.234127  [    0/ 9393]\n",
      "loss: 1.167963  [ 3200/ 9393]\n",
      "loss: 1.155536  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.041275 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.228908  [    0/ 9393]\n",
      "loss: 1.214130  [ 3200/ 9393]\n",
      "loss: 1.340760  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.040746 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.301103  [    0/ 9393]\n",
      "loss: 1.215858  [ 3200/ 9393]\n",
      "loss: 1.136050  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.040918 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.311789  [    0/ 9393]\n",
      "loss: 1.248583  [ 3200/ 9393]\n",
      "loss: 1.210772  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 0.040961 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.214258  [    0/ 9393]\n",
      "loss: 1.248716  [ 3200/ 9393]\n",
      "loss: 1.250517  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.040049 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.219245  [    0/ 9393]\n",
      "loss: 1.185932  [ 3200/ 9393]\n",
      "loss: 1.311621  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.040469 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.308448  [    0/ 9393]\n",
      "loss: 1.279717  [ 3200/ 9393]\n",
      "loss: 1.249018  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.040288 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.131557  [    0/ 9393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.216730  [ 3200/ 9393]\n",
      "loss: 1.179611  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.040420 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.147297  [    0/ 9393]\n",
      "loss: 1.195867  [ 3200/ 9393]\n",
      "loss: 1.342494  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.040475 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.246065  [    0/ 9393]\n",
      "loss: 1.055525  [ 3200/ 9393]\n",
      "loss: 1.163686  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.040554 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.154819  [    0/ 9393]\n",
      "loss: 1.152788  [ 3200/ 9393]\n",
      "loss: 1.334783  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 0.040837 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.329658  [    0/ 9393]\n",
      "loss: 1.281686  [ 3200/ 9393]\n",
      "loss: 1.274939  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.040870 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.124271  [    0/ 9393]\n",
      "loss: 1.107219  [ 3200/ 9393]\n",
      "loss: 1.154930  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.040244 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.257088  [    0/ 9393]\n",
      "loss: 1.200525  [ 3200/ 9393]\n",
      "loss: 1.252662  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.040419 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.216525  [    0/ 9393]\n",
      "loss: 1.071339  [ 3200/ 9393]\n",
      "loss: 1.217689  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.040483 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.278553  [    0/ 9393]\n",
      "loss: 1.281104  [ 3200/ 9393]\n",
      "loss: 1.154687  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.040618 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.289013  [    0/ 9393]\n",
      "loss: 1.245124  [ 3200/ 9393]\n",
      "loss: 1.309779  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 0.040672 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.141084  [    0/ 9393]\n",
      "loss: 1.279386  [ 3200/ 9393]\n",
      "loss: 1.157925  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.040318 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.182994  [    0/ 9393]\n",
      "loss: 1.342096  [ 3200/ 9393]\n",
      "loss: 1.314445  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.040334 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.154704  [    0/ 9393]\n",
      "loss: 1.140840  [ 3200/ 9393]\n",
      "loss: 1.188506  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 0.041176 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.280985  [    0/ 9393]\n",
      "loss: 1.248582  [ 3200/ 9393]\n",
      "loss: 1.217453  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.040575 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.123580  [    0/ 9393]\n",
      "loss: 1.373589  [ 3200/ 9393]\n",
      "loss: 1.246147  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.040514 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.280548  [    0/ 9393]\n",
      "loss: 1.496431  [ 3200/ 9393]\n",
      "loss: 1.309282  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.040185 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.215666  [    0/ 9393]\n",
      "loss: 1.248252  [ 3200/ 9393]\n",
      "loss: 1.279311  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.040399 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.186545  [    0/ 9393]\n",
      "loss: 1.185915  [ 3200/ 9393]\n",
      "loss: 1.217048  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.040209 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 1.154846  [    0/ 9393]\n",
      "loss: 1.115817  [ 3200/ 9393]\n",
      "loss: 1.159131  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.040387 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.250207  [    0/ 9393]\n",
      "loss: 1.222013  [ 3200/ 9393]\n",
      "loss: 1.077754  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.039809 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.247366  [    0/ 9393]\n",
      "loss: 1.334513  [ 3200/ 9393]\n",
      "loss: 1.222877  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.040561 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.030129  [    0/ 9393]\n",
      "loss: 1.186066  [ 3200/ 9393]\n",
      "loss: 1.123535  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.040482 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.193778  [    0/ 9393]\n",
      "loss: 1.279711  [ 3200/ 9393]\n",
      "loss: 1.124079  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.040560 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 1.273020  [    0/ 9393]\n",
      "loss: 1.142954  [ 3200/ 9393]\n",
      "loss: 1.216990  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.039971 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.248098  [    0/ 9393]\n",
      "loss: 1.118204  [ 3200/ 9393]\n",
      "loss: 1.309966  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.040330 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 1.230104  [    0/ 9393]\n",
      "loss: 1.322997  [ 3200/ 9393]\n",
      "loss: 1.216951  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.039667 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.341737  [    0/ 9393]\n",
      "loss: 1.275273  [ 3200/ 9393]\n",
      "loss: 1.121443  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.040223 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.247485  [    0/ 9393]\n",
      "loss: 1.222676  [ 3200/ 9393]\n",
      "loss: 1.154143  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.039983 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 1.090610  [    0/ 9393]\n",
      "loss: 1.249621  [ 3200/ 9393]\n",
      "loss: 1.125533  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.039988 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.318630  [    0/ 9393]\n",
      "loss: 1.276330  [ 3200/ 9393]\n",
      "loss: 1.185440  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.041392 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.337944  [    0/ 9393]\n",
      "loss: 1.185955  [ 3200/ 9393]\n",
      "loss: 1.123575  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.039992 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 1.154451  [    0/ 9393]\n",
      "loss: 1.273036  [ 3200/ 9393]\n",
      "loss: 1.090599  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.039638 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 1.157621  [    0/ 9393]\n",
      "loss: 1.279833  [ 3200/ 9393]\n",
      "loss: 1.371015  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.040972 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.222394  [    0/ 9393]\n",
      "loss: 1.205831  [ 3200/ 9393]\n",
      "loss: 1.188147  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.039767 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.215869  [    0/ 9393]\n",
      "loss: 1.306273  [ 3200/ 9393]\n",
      "loss: 1.143718  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.039552 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.279728  [    0/ 9393]\n",
      "loss: 1.276771  [ 3200/ 9393]\n",
      "loss: 1.185651  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 0.041024 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.265142  [    0/ 9393]\n",
      "loss: 1.342314  [ 3200/ 9393]\n",
      "loss: 1.278461  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.039880 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 1.189020  [    0/ 9393]\n",
      "loss: 1.272509  [ 3200/ 9393]\n",
      "loss: 1.217329  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.040060 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.186101  [    0/ 9393]\n",
      "loss: 1.100627  [ 3200/ 9393]\n",
      "loss: 1.278003  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.040218 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.186339  [    0/ 9393]\n",
      "loss: 1.152075  [ 3200/ 9393]\n",
      "loss: 1.218098  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.040279 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 1.164326  [    0/ 9393]\n",
      "loss: 1.153535  [ 3200/ 9393]\n",
      "loss: 1.233119  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.039250 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.279850  [    0/ 9393]\n",
      "loss: 1.279832  [ 3200/ 9393]\n",
      "loss: 1.279832  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.040345 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.279811  [    0/ 9393]\n",
      "loss: 1.296319  [ 3200/ 9393]\n",
      "loss: 1.277099  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.039623 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.215297  [    0/ 9393]\n",
      "loss: 1.180052  [ 3200/ 9393]\n",
      "loss: 1.228853  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.040259 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 1.092362  [    0/ 9393]\n",
      "loss: 1.191193  [ 3200/ 9393]\n",
      "loss: 1.154832  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.040396 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 1.186003  [    0/ 9393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.279830  [ 3200/ 9393]\n",
      "loss: 1.153810  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.040432 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.246572  [    0/ 9393]\n",
      "loss: 1.123583  [ 3200/ 9393]\n",
      "loss: 1.155015  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.040254 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 1.279797  [    0/ 9393]\n",
      "loss: 1.012326  [ 3200/ 9393]\n",
      "loss: 1.186075  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.039983 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.216769  [    0/ 9393]\n",
      "loss: 1.181969  [ 3200/ 9393]\n",
      "loss: 1.247764  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 0.040090 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 1.244818  [    0/ 9393]\n",
      "loss: 1.184374  [ 3200/ 9393]\n",
      "loss: 1.154836  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.040158 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 1.217330  [    0/ 9393]\n",
      "loss: 1.248483  [ 3200/ 9393]\n",
      "loss: 1.301469  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.040762 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 1.246247  [    0/ 9393]\n",
      "loss: 1.248577  [ 3200/ 9393]\n",
      "loss: 1.031881  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.040265 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 1.185776  [    0/ 9393]\n",
      "loss: 1.250154  [ 3200/ 9393]\n",
      "loss: 1.185843  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.039782 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.274440  [    0/ 9393]\n",
      "loss: 1.318538  [ 3200/ 9393]\n",
      "loss: 1.032800  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 0.039713 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 1.126973  [    0/ 9393]\n",
      "loss: 1.180103  [ 3200/ 9393]\n",
      "loss: 1.216695  [ 6400/ 9393]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.040511 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 100  # 학습을 원하는 만큼 수정요\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c82888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
